{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from scipy.stats.distributions import skewnorm\n",
    "from scipy.optimize import leastsq\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from densitycontour import densitycontour\n",
    "from string import join\n",
    "\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc(\"font\", size=20)\n",
    "rc(\"text\", usetex=True, **{\"latex.preamble\":r\"\\usepackage{amsmath},\\usepackage{times},\\usepackage{eulervm}\", \"hinting\":\"native\"})\n",
    "rc(\"figure\", figsize=(5,5))\n",
    "rc(\"axes\", linewidth=0.3)\n",
    "rc(\"xtick.major\", width=0.3)\n",
    "rc(\"ytick.major\", width=0.3)\n",
    "rc(\"xtick.minor\", width=0.3)\n",
    "rc(\"ytick.minor\", width=0.3)\n",
    "rc(\"xtick\", labelsize=\"x-small\")\n",
    "rc(\"ytick\", labelsize=\"x-small\")\n",
    "rc(\"hatch\", linewidth=0.5)\n",
    "rc(\"grid\", linewidth=0.3)\n",
    "rc(\"savefig\", format=\"pdf\", dpi=50, bbox=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modelo real\n",
    "def real_model(x, params):\n",
    "    return x**params[0]+params[1]\n",
    "# modelo propuesto\n",
    "def model(x, params):\n",
    "    return params[0]*x+params[1]\n",
    "# definir verosimilitud del modelo asumido para reproducir cada observación\n",
    "def lik_i(x, y, sigma, params):\n",
    "    return 1.0/sqrt(2*pi*sigma**2)*exp(-((model(x, params)-y)/(2*sigma))**2)\n",
    "# definir verosimilitud verdadera del modelo asumido para reproducir cada observación\n",
    "def real_lik_i(x, y, sigma, params):\n",
    "    return 1.0/sqrt(2*pi*sigma**2)*exp(-((real_model(x, params)-y)/(2*sigma))**2)\n",
    "# definir prior objetivo\n",
    "def naive_prior(m, b, **kwargs):\n",
    "    return ones(m.shape)*1.0/(m.max()-m.min())*1.0/(b.max()-b.min())\n",
    "# definir prior informativo\n",
    "def inf_prior(m, b, mu_m=1.0, sigma_m=0.5, mu_b=-1.0, sigma_b=1.0):\n",
    "    return normpdf(m, mu_m, sigma_m) * normpdf(b, mu_b, sigma_b)\n",
    "# definir clipping\n",
    "def last(nbin, span):\n",
    "    return span[0], span[-1]+diff(span)/nbin\n",
    "# definir log enmascarado\n",
    "def masked_log(PDF):\n",
    "    PDF_ = copy(PDF)\n",
    "    PDF_[PDF_==0.0] = 1.0\n",
    "    PDF_ = log(PDF_)\n",
    "    PDF_[PDF_==0.0] = np.nan\n",
    "    return PDF_\n",
    "# definir integral volumetrica\n",
    "def integrate_vol(support, PDF, axis=None, mask=None):\n",
    "    volume = copy(PDF)\n",
    "    if axis==None:\n",
    "        volume = (0.5*(volume[:-1]+volume[1:])*diff(support[0],axis=0)).sum(axis=0)\n",
    "        volume = (0.5*(volume[:-1]+volume[1:])*diff(unique(support[1]))).sum()\n",
    "    else:\n",
    "        indices = arange(volume.shape[axis], dtype=np.int)\n",
    "        h = 0.5*(volume.take(indices[1:],axis)+volume.take(indices[:-1],axis))\n",
    "        volume = (h*diff(support[axis],axis=axis)).sum(axis=axis)\n",
    "    return volume\n",
    "# definir normalización al máximo valor\n",
    "def norm_to_max(PDF, return_min_max=False):\n",
    "    PDF_ = copy(PDF)\n",
    "    if any(PDF!=PDF[0]):\n",
    "        min_ = PDF_.min()\n",
    "        PDF_ -= min_\n",
    "    max_ = PDF_.max()\n",
    "    PDF_ /= max_\n",
    "    if return_min_max: return PDF_, min_, max_\n",
    "    else: return PDF_\n",
    "# definir normalización al volumen\n",
    "def norm_to_vol(support, PDF, return_vol=False):\n",
    "    PDF_ = copy(PDF)\n",
    "    volume = integrate_vol(support, PDF_)\n",
    "    PDF_ /= volume\n",
    "    if return_vol: return PDF_, volume\n",
    "    else: return PDF_\n",
    "# definir calculo del nivel ~ percentile\n",
    "def percentile_to_level(X, Y, PDF, percentile, tol=1e-4, max_iter=1000):\n",
    "    PDF_ = copy(PDF)\n",
    "    PDF_, Z_min, Z_max = norm_to_max(PDF_, return_min_max=True)\n",
    "    if percentile==100.0: return Z_min\n",
    "    if percentile==0.0: return Z_max\n",
    "    \n",
    "    volume = integrate_vol([X,Y], PDF_)\n",
    "    step = -0.1\n",
    "    delta = 999.9\n",
    "    levels = [1.0]\n",
    "    pers = [0.0]\n",
    "    while True:\n",
    "        mask = PDF_>=levels[-1]+step\n",
    "        Z = copy(PDF_)\n",
    "        Z[~mask] = 0.0\n",
    "        pseudo_vol = integrate_vol([X,Y], Z)\n",
    "        levels.append(levels[-1]+step)\n",
    "        pers.append(pseudo_vol/volume)\n",
    "        delta = percentile-pers[-1]\n",
    "        if tol>abs(delta) or len(levels)>=max_iter: break\n",
    "        if (delta>0 and step>0) or (delta<0 and step<0): step *= -1.0\n",
    "        if levels[-1]+step in levels: step *= 0.5\n",
    "    levels[-1] *= Z_max\n",
    "    if any(PDF!=PDF[0]):\n",
    "        levels[-1] += Z_min\n",
    "    return levels[-1]\n",
    "# definir función para muestrear distribuciones arbitrarias\n",
    "def rejection_sampling(support, PDF, n_samples=100, return_grid=False, grid_steps=None):\n",
    "    X, Y = support\n",
    "    Z, Z_min, Z_max = norm_to_max(copy(PDF), return_min_max=True)\n",
    "    \n",
    "    Z_prop = random.rand(*Z.shape)\n",
    "    mask = Z_prop<=Z\n",
    "    x, y, z = X[mask].ravel(), Y[mask].ravel(), Z[mask].ravel()\n",
    "    z *= Z_max\n",
    "    z += Z_min\n",
    "    if n_samples<mask.sum():\n",
    "        idx = random.choice(arange(mask.sum(), dtype=np.int), size=n_samples, replace=False)\n",
    "        x, y, z = x[idx], y[idx], z[idx]\n",
    "    if return_grid:\n",
    "        ranges = [(r.min(),r.max()) for r in (x,y)]\n",
    "        if grid_steps==None: grid_steps_ = (100,)*len(ranges)\n",
    "        else: grid_steps_ = grid_steps\n",
    "        xi, yi = [linspace(ranges[i][0],ranges[i][1],grid_steps_[i]) for i in xrange(len(ranges))]\n",
    "        zi = griddata(x, y, z, xi, yi, interp=\"linear\")\n",
    "        return x, y, xi, yi, zi\n",
    "    else:\n",
    "        return x, y\n",
    "\n",
    "random.seed(0)\n",
    "# definir variables del espacio de parámetros, observaciones y PDFs\n",
    "percentiles = [0.99, 0.95, 0.68]\n",
    "N_obs = 20\n",
    "N_uni = 100\n",
    "N_par = 200\n",
    "shape = (N_uni, N_par, N_par)\n",
    "range_x = (0, 10)\n",
    "range_y = (-15, 45)\n",
    "range_m, range_b = (-20.0, +20.0), (-100.0, +100.0)\n",
    "range_pdf = (0.0, 1.2)\n",
    "X = linspace(range_x[0], range_x[1], shape[0])\n",
    "M = linspace(range_m[0], range_m[1], shape[1])\n",
    "B = linspace(range_b[0], range_b[1], shape[2])\n",
    "# simulación de la observaciones\n",
    "x = sort(X[0]+random.rand(N_obs)*(X[-1]-X[0]))\n",
    "mask_linear = x>4.0\n",
    "mask_potent = x>0.0\n",
    "sk, mu, sigma = 3.0, -0.55, 1.2\n",
    "sk, mu, sigma = 0.0, 0.0, 8.0\n",
    "real_params = (1.5, 0.0)\n",
    "y = real_model(x, real_params) + skewnorm.rvs(sk, mu, sigma, size=N_obs)\n",
    "XX_obs, MM_obs, BB_obs = meshgrid(x[mask_linear], M, B, indexing=\"ij\")\n",
    "YY_obs, MM_obs, BB_obs = meshgrid(y[mask_linear], M, B, indexing=\"ij\")\n",
    "# simular universo de observaciones \"sin ruido\"\n",
    "XX_uni, MM_uni, BB_uni = meshgrid(X, M, B, indexing=\"ij\")\n",
    "YY_uni = real_model(XX_uni, real_params) + skewnorm.rvs(sk, mu, 0.01, size=XX_uni.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAFLCAYAAADs/4aEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f690286dd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mostrar primero el modelo propuesto\n",
    "# mostrar observaciones\n",
    "fig_dat, ax = subplots(1, 1)\n",
    "ax.errorbar(x[mask_linear], y[mask_linear], sigma, fmt=\".\", ecolor=\"0.2\", color=\"0.2\", lw=0.5)\n",
    "ax.set_xlim(*range_x)\n",
    "ax.set_ylim(*range_y)\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "ax.set_ylabel(r\"$y$\")\n",
    "fig_dat.savefig(\"img/data-linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_pdf, axs = subplots(2, 5, figsize=(15,5), sharex=\"row\", sharey=True)\n",
    "for ax in axs.ravel(): ax.set_visible(False)\n",
    "fig_pdf.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "axs[0,0].set_ylabel(r\"$\\text{FDD}/\\text{FDD}_\\text{max}$\")\n",
    "axs[1,0].set_ylabel(r\"$\\text{FDD}/\\text{FDD}_\\text{max}$\")\n",
    "axs[0,0].set_xlim(*range_m)\n",
    "axs[0,0].set_ylim(*range_pdf)\n",
    "axs[1,0].set_xlim(*range_b)\n",
    "\n",
    "x_idx = digitize(x[mask_linear], linspace(x[mask_linear].min(),x[mask_linear].max(),axs.shape[1]+1), right=True)\n",
    "x_idx[x_idx==0] = 1\n",
    "\n",
    "inf_pars = dict(mu_m=10.0, sigma_m=5.0, mu_b=0.0, sigma_b=50.0)\n",
    "prior = inf_prior(MM_obs[0,:,:], BB_obs[0,:,:], **inf_pars)\n",
    "\n",
    "show_condlikelihood = True\n",
    "show_marginals = True\n",
    "show_prior = False\n",
    "show_marglikelihood = False\n",
    "show_posterior = False\n",
    "mask_names = array([show_condlikelihood, show_marginals, show_marglikelihood, show_prior, show_posterior])\n",
    "names = array([\"mle\", \"mar\", \"mml\", \"prior\", \"posterior\"])\n",
    "for j,i in it.product(xrange(axs.shape[1]),xrange(axs.shape[0])):\n",
    "    mask = x_idx<=j+1\n",
    "    likelihood = lik_i(XX_obs[mask,:,:], YY_obs[mask,:,:], sigma, [MM_obs[mask,:,:],BB_obs[mask,:,:]]).prod(axis=0)\n",
    "    mle_m, mle_b = unravel_index(argmax(likelihood), likelihood.shape)\n",
    "    lik_min = np.min(likelihood)\n",
    "    lik_max = likelihood[mle_m,mle_b]-lik_min\n",
    "    margin_m = range(0, mle_m-10+j, 10-j) + range(mle_m+10-j, M.size, 10-j)\n",
    "    margin_b = range(0, mle_b-10+j, 10-j) + range(mle_b+10-j, B.size, 10-j)\n",
    "    posterior = likelihood*prior\n",
    "    if axs[i,j].is_first_row():\n",
    "        pri_m = integrate_vol([MM_obs[0],BB_obs[0]], prior, axis=1)\n",
    "        lik_m = integrate_vol([MM_obs[0],BB_obs[0]], likelihood, axis=1)\n",
    "        pos_m = integrate_vol([MM_obs[0],BB_obs[0]], posterior, axis=1)\n",
    "        mml_m = argmax(lik_m)\n",
    "        map_m = argmax(pos_m)\n",
    "        \n",
    "        axs[i,j].set_title(r\"$N={}$\".format(mask.sum()), size=\"medium\")\n",
    "        \n",
    "        axs[i,j].plot(M, norm_to_max(likelihood[:,mle_b]), \":\", color=\"0.2\", lw=1.5, visible=show_condlikelihood)\n",
    "        for mar_b in margin_b:\n",
    "            axs[i,j].plot(M, (likelihood[:,mar_b]-lik_min)/lik_max, \"-\", color=\"0.7\", lw=0.5, zorder=-1, visible=show_marginals)\n",
    "        axs[i,j].plot(M, norm_to_max(lik_m), \"-\", color=\"0.2\", lw=1.5, visible=show_marglikelihood)\n",
    "        axs[i,j].fill_between(M, norm_to_max(pri_m), lw=0.0, hatch=5*\"/\", edgecolor=\"0.7\", facecolor=\"none\", visible=show_prior)\n",
    "        axs[i,j].plot(M, norm_to_max(pos_m), \"-\", color=\"C0\", lw=1.5, visible=show_posterior)\n",
    "        axs[i,j].plot(M[mml_m], 1.05, \"v\", mfc=\"0.2\", mec=\"0.2\", visible=show_marglikelihood)\n",
    "        axs[i,j].plot(M[map_m], 1.05, \"v\", mfc=\"C0\", mec=\"C0\", visible=show_posterior)\n",
    "        axs[i,j].plot(M[mle_m], 1.15, \"v\", mfc=\"none\", mec=\"0.2\", visible=show_condlikelihood)\n",
    "        axs[i,j].set_xlabel(r\"$m$\")\n",
    "    if axs[i,j].is_last_row():\n",
    "        pri_b = integrate_vol([MM_obs[0],BB_obs[0]], prior, axis=0)\n",
    "        lik_b = integrate_vol([MM_obs[0],BB_obs[0]], likelihood, axis=0)\n",
    "        pos_b = integrate_vol([MM_obs[0],BB_obs[0]], posterior, axis=0)\n",
    "        mml_b = argmax(lik_b)\n",
    "        map_b = argmax(pos_b)\n",
    "        \n",
    "        axs[i,j].plot(B, norm_to_max(likelihood[mle_m,:]), \":\", color=\"0.2\", lw=1.5, visible=show_condlikelihood)\n",
    "        for mar_m in margin_m:\n",
    "            axs[i,j].plot(B, (likelihood[mar_m,:]-lik_min)/lik_max, \"-\", color=\"0.7\", lw=0.5, zorder=-1, visible=show_marginals)\n",
    "        axs[i,j].plot(B, norm_to_max(lik_b), \"-\", color=\"0.2\", lw=1.5, visible=show_marglikelihood)\n",
    "        axs[i,j].fill_between(B, norm_to_max(pri_b), lw=0.0, hatch=5*\"/\", edgecolor=\"0.7\", facecolor=\"none\", visible=show_prior)\n",
    "        axs[i,j].plot(B, norm_to_max(pos_b), \"-\", lw=1.5, color=\"C0\", visible=show_posterior)\n",
    "        axs[i,j].plot(B[mml_b], 1.05, \"v\", mfc=\"0.2\", mec=\"0.2\", visible=show_marglikelihood)\n",
    "        axs[i,j].plot(B[map_b], 1.05, \"v\", mfc=\"C0\", mec=\"C0\", visible=show_posterior)\n",
    "        axs[i,j].plot(B[mle_b], 1.15, \"v\", mfc=\"none\", mec=\"0.2\", visible=show_condlikelihood)\n",
    "        axs[i,j].set_xlabel(r\"$b$\")\n",
    "    if i==1:\n",
    "        fig_fit, ax = subplots(1, 1)\n",
    "        ax.set_title(r\"$N={}$\".format(mask.sum()), size=\"medium\")\n",
    "        ax.plot(X, model(X, [M[mle_m],B[mle_b]]), \"-\", color=\"0.2\", lw=1.5, visible=show_condlikelihood)\n",
    "        ax.plot(X, model(X, [M[map_m],B[map_b]]), \"-\", color=\"C0\", lw=1.5, visible=show_posterior)\n",
    "        ax.errorbar(x[mask_linear][~mask], y[mask_linear][~mask], sigma, fmt=\".\", ecolor=\"0.7\", color=\"0.7\", lw=0.5)\n",
    "        ax.errorbar(x[mask_linear][mask], y[mask_linear][mask], sigma, fmt=\".\", ecolor=\"0.2\", color=\"0.2\", lw=0.5)\n",
    "        ax.set_xlim(*range_x)\n",
    "        ax.set_ylim(*range_y)\n",
    "        ax.set_xlabel(r\"$x$\")\n",
    "        ax.set_ylabel(r\"$y$\")\n",
    "        \n",
    "        axs[0,j].set_visible(True)\n",
    "        axs[1,j].set_visible(True)\n",
    "        \n",
    "        if any(mask_names): fig_fit.savefig(\"img/linear-fit-{}-{}\".format(join(names[mask_names], \"-\"), j+1))\n",
    "        if any(mask_names): fig_pdf.savefig(\"img/linear-pdf-{}-{}\".format(join(names[mask_names], \"-\"), j+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mle = True\n",
    "show_likelihood = True\n",
    "show_cond_b = False\n",
    "show_cond_m = False\n",
    "mask_names = array([show_mle, show_likelihood, show_cond_m, show_cond_b])\n",
    "names = array([\"mle\", \"likelihood\", \"condm\", \"condb\"])\n",
    "\n",
    "fig_par, ax = subplots(1, 1)\n",
    "likelihood = lik_i(XX_obs, YY_obs, sigma, [MM_obs,BB_obs]).prod(axis=0)\n",
    "mle_m, mle_b = unravel_index(argmax(likelihood), likelihood.shape)\n",
    "levels = array([percentile_to_level(MM_obs[0],BB_obs[0],likelihood,per) for per in percentiles])\n",
    "if show_likelihood:\n",
    "    ax.contour(MM_obs[0], BB_obs[0], likelihood, levels, colors=\"0.2\", linewidths=0.7)\n",
    "ax.plot(M[mle_m], B[mle_b], \"o\", mfc=\"0.2\", mec=\"0.2\", visible=show_mle)\n",
    "ax.axvline(M[mle_m], ls=\"--\", lw=0.7, color=\"0.2\", visible=show_cond_b)\n",
    "ax.axhline(B[mle_b], ls=\"--\", lw=0.7, color=\"0.2\", visible=show_cond_m)\n",
    "ax.set_xlim(2.0, 10.0)\n",
    "ax.set_ylim(-50.0, 0.0)\n",
    "ax.set_xlabel(r\"$m$\")\n",
    "ax.set_ylabel(r\"$b$\")\n",
    "fig_par.savefig(\"img/pars-{}\".format(join(names[mask_names], \"-\") if any(mask_names) else \"blank\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PARA MLE\n",
    "# en cada iteración:\n",
    "#X mostrar el ajuste lineal\n",
    "#X mostrar de la verosimilitud\n",
    "# explicar como se llega al máximo de la verosimilitud\n",
    "# explicar que rara vez se cuenta con buen muestreo de la verosimilitud en el espacio de parámetros\n",
    "# explicar que la incertidumbre en los parámetros no es realista porque no hay propagación\n",
    "#X mostrar el plano [m,b]\n",
    "#X mostrar la solución MLE en [m,b]\n",
    "#X mostrar los contornos de la verosimilitud\n",
    "# explicar que no se puede conocer con infinita precisión ambos parámetros simultáneamente porque están degenerados\n",
    "\n",
    "# PARA EXPLICAR MARGINALIZACIÓN\n",
    "# mostrar verosimilitud de m, condicional en varios valores de b\n",
    "# mostrar verosimilitud de b, condicional en varios valores de m\n",
    "# mostrar en ambos casos la distribución marginalizada\n",
    "# explicar que la marginalización es una forma de propagar la incertidumbre de un parámetro a otro\n",
    "# explicar que el máximo de la verosimilitud es el mejor punto de partida para muestrear el espacio de parámetros:\n",
    "# todo se ve mejor desde la cima\n",
    "\n",
    "# PARA BAYES\n",
    "# en cada iteración:\n",
    "# mostrar el ajuste lineal con los intervalos de confianza (muestrear la distribución posterior para esto)\n",
    "# mostrar la distribución previa\n",
    "# mostrar la verosimilitud (condicional y marginalizada)\n",
    "# mostrar la distribución posterior\n",
    "# explicar que el parecido entre la verosimilitud y la distribución posterior es un efecto muy deseado\n",
    "# explicar las interpretaciones de la verosimilitud como función y como distribución de probabilidad y su rol para Bayes\n",
    "# explicar que Bayes es la actualización de la distribución previa a través del peso impuesto por los datos\n",
    "# explicar la diferencia entre la verosimilitud y la distribución posterior:\n",
    "# la verosimilitud es la respuesta a ¿qué tan probables son las observaciones suponiendo que estos son Gaussianos\n",
    "# y que el modelo y los parámetros propuestos representan el universo de observaciones?\n",
    "# la distribución posterior, en cambio, es la respuesta a ¿qué tan probables son estos parámetros para describir\n",
    "# las observaciones hechas, suponiendo que estos obedecen al modelo propuesto?\n",
    "# con Bayes se reconoce que hay incertidumbre sobre los parámetros y se les da un carácter probabilístico, no así con MV\n",
    "\n",
    "# PARA EFECTO DE LA DISTRIBUCIÓN PREVIA\n",
    "# usar una distribución previa informativa y mask_linear\n",
    "# fijando SNR (alta) y variando N, en cada iteración:\n",
    "# mostrar el ajuste lineal con los intervalos de confianza\n",
    "# mostrar la distribución posterior\n",
    "# explicar que en el límite de N infinito, la distribución previa no es relevante siempre que las observaciones sean\n",
    "# informativas sobre los parámetros y el modelo sea el correcto\n",
    "# fijando N y variando SNR, en cada iteración:\n",
    "# mostrar el ajuste lineal con los intervalos de confianza\n",
    "# mostrar la distribución posterior\n",
    "# explicar que en el límite de SNR infinito, la distribución previa no es relevante siempre que las N observaciones sean\n",
    "# informativas sobre los parámetros y el modelo sea el correcto\n",
    "\n",
    "# PARA EXPLICAR EL MÉTODO DE MÁXIMA ENTROPÍA\n",
    "# plantear el problema de la FIM\n",
    "# usar el método de los multiplicadores de Lagrange para conseguir la FIM de Salpeter\n",
    "# explicar que esto sugiere que la FIM tiene un origen estocástico\n",
    "\n",
    "# PARA VALORACIÓN DEL MODELO\n",
    "# simular datos con muy buena SNR usando la máscara mask_potent\n",
    "# usando varios ejempos de distribución previa informativa:\n",
    "# mostrar el ajuste lineal con los intervalos de confianza en cada caso\n",
    "# mostrar el modelo real\n",
    "# explicar que usando una buena distribución previa, no es posible incluir el efecto de haber elegido mal el modelo\n",
    "# explicar como valorar el modelo usando la distribución posterior predictiva\n",
    "# mostrar la probabilidad de haber observado los nuevos datos si estos estuvieran basados en el modelo lineal\n",
    "# explicar que la distribución posterior predictiva puede verse como la aplicación de Bayes usando la distribución\n",
    "# posterior como distribución previa, permitiendo actualizar el modelo usando la verosimilitud correcta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
