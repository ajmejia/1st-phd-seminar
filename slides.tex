\documentclass[a4paper,twoside]{article}

\usepackage{amsmath}
\usepackage{bm}
\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{pxfonts}
\usepackage[dvipsnames]{xcolor}
\usepackage{xspace}

\usepackage{marginnote}
\usepackage[top=1.5cm,bottom=1.5cm,outer=6cm,inner=4cm,heightrounded,marginparwidth=4cm,%
            marginparsep=1.2cm]{geometry}

\newcommand{\note}[1]{\color{OrangeRed}(#1)\xspace}
\newcommand{\definition}[2]{\marginnote{{\color{teal}#1:} #2}}

\newcommand{\Hip}{\ensuremath{\bm{\Theta}}\xspace}
\newcommand{\hip}{\ensuremath{\bm{\theta}}\xspace}
\newcommand{\dat}{\ensuremath{\{\mathcal{D}\}}\xspace}
\newcommand{\pos}[2]{\ensuremath{\pi_N\left(#1|#2\right)}\xspace}
\newcommand{\pri}[2]{\ensuremath{\pi_0\left(#1|#2\right)}\xspace}
\newcommand{\pro}[1]{\ensuremath{Pr\left(#1\right)}\xspace}

\title{Inferencia en el marco de la Estadística Bayesiana}
\author{Alfredo Mejía-Narváez}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
%
La estadística bayesiana no es solo un conjunto de reglas diseñadas para la interpretación de los
datos en nuevo conocimiento dada la experiencia previa, es una forma de pensar. De la gran mayoría
de los libros de estadística aprendemos a responder a la pregunta equivocada o, al menos, una que
realmente nos es la que nos interesa como científicos: dado que tenemos conocimiento absoluto del
estado del problema (e.g., el modelo con el cual describimos los datos con sus estadísticas
correspondientes), ¿cuál es la probabilidad de haber obervado los datos?. La estadística bayesiana
no solo nos permite responder a la pregunta de interés científico, sino que nos permite darle una
respuesta lo más objetivamente posible, mediante probabilidades. Entonces, la pregunta de interés es
en general: dados la experiencia previa (nuestro grado de conocimiento del problema en ausencia de
los datos) y los datos ¿qué podemos inferir para incrementar nuestro grado de conocimiento del
problema?. En este seminario les presentaré el esquema general de la inferencia bayesiana, algunas
de sus aplicaciones en la astrofísica y dos ejemplos: uno de juguete para ilustrar conceptos básicos
y otro de la vida real.
%
\end{abstract}

\section{Introducción: estadística básica}

El concepto de probabilidad ha venido a responder una pregunta fundamental para el ciencia y otras
áreas del conocimiento en general: ¿cuál es el grado de certidumbre que poseemos sobre un evento,
dado conocimiento relevante de fondo?. En este sentido, una vez nuestro grado de certidumbre sobre
un evento queda por sentado también así queda nuestro grado de intertidumbre. Por ejemplo, si
sabemos que existe un $74\%$ de probabilidad de que llueva, sabemos que existe un $26\%$ de que no.
Es en esta \emph{completitud} en la que yace la mayor fortaleza del concepto de probabilidad y que
es y debe ser particularmente apreciado en las ramas del conocimiento científico.

Las operaciones matemáticas sobre las cuales se construyen las bases de una teoría de probabilidad
son bastante simples y están bien definidas. Hoy en día se conocen como las reglas de Cox y
matemáticamente se resumen en dos ecuaciones
%
\begin{equation}\label{ec:norm}
  P(\theta|I) + P(\bar{\theta}|I) = 1
\end{equation}
%
\definition{$P(\theta|I)$}{es nuestro grado de conocimiento sobre una hipótesis o premisa $\theta$
condicionado sobre $I$. En el sentido más general $\theta$ puede representar un vector, $\hip$, en
el espacio de hipótesis, $\Hip$.} y
%
\begin{equation}
  P(\theta_1,\theta_2|I) = P(\theta_1|\theta_2,I)\times P(\theta_2|I)
\end{equation}
%
En lenguaje cotidiano, la primera ecuación nos dice que dado nuestro grado de conocimiento
(probabilidad) de conjunto exhaustivo y mutuamente excluyente de posibilidades, podemos asignar
inmediatamente nuestro grado de desconocimiento (o ignorancia sobre el mismo conjunto). Ambas
cantidades sumadas forman una \emph{certeza}; la segunda ecuación nos dice que dado nuestro grado de
conocimiento de $\theta_2$ y nuestro grado de conocimiento en $\theta_1$ condicionado en $\theta_2$,
podemos admitir que sabemos nuestro grado de conocimiento de $\theta_1$ y $\theta_2$.

\section{El teorema de Bayes}
%
\definition{$P(\hip|\dat,I)$}{es la distribución de probabilidad posterior y representa nuestro
grado de conocimiento de la hipótesis a la luz de los datos, $\dat$.}
%
El teorema de Bayes se desprende de estas dos simples relaciones y sostiene que
%
\begin{equation}\label{ec:bayes}
P(\hip|\dat,I) = \frac{P(\dat|\hip,I)\times P(\hip|I)}{P(\dat|I)},
\end{equation}
%
donde
%
\begin{equation*}
P(\dat|I) = \int_{\Hip}P(\hip|\dat,I)\text{d}\hip.
\end{equation*}
%
\definition{$P(\dat|I)$}{se conoce como la evidencia y es la distribución posterior marginalizada
sobre el espacio de parámetros.}
%
El poder del teorema de Bayes en sí yace en nuestra capacidad para asignar las distribuciones
(densidades en realidad) de probabilidad en el lado derecho de la igualdad, $P(\dat|\hip,I)$ y
$P(\hip|I)$, en la Ec.~\eqref{ec:bayes}. Mientras esto es usualmente cierto en el caso de la última
distribución, pues esta refleja simplemente \emph{nuestro grado de conocimiento (ignorancia y/o
prejuicios) sobre problema previo a la obtención de los datos}, la primera distribución de
probabilidades por otra parte, requiere un poco más de elaboración y conocimiento (probablemente
también prejuicios) sobre los datos, pues representa la \emph{plausibilidad de la hipótesis asumida
a la luz de los datos}.

\section{Inferencia bayesiana}
%
La inferencia bayesiana es la técnica que consiste en calcular la distribución de probabilidad
posterior, $P(\hip|\dat,I)$. El primer paso es construir la función que describe la probabilidad de
haber hecho la observación suponiendo la hipótesis como correcta y la distribución prior que
describe nuestro grado de conocimiento de la hipótesis antes de haber hecho la observación (véase el
paréntesis A). Ambas distribuciones de probabilidad requieren de nuestro conocimiento del problema,
pero en particular, la distribución \emph{likelihood} solo se puede concebir correctamente si
conocemos también los datos (e.g., los errores son Gaussianos, las observaciones son naturalmente
poco probables, el número de posibilidades es bajo, etc.).

La elección de la distribución de probabilidad prior, por otra parte, representa un problema más
complejo y que muchas veces es desestimado. Existen básicamente dos clases de distribuciones prior:
las subjetivas que permiten que el científico introduzca sus prejuicios y las objetivas
caracterizados generalmente por una distribución plana con la que solo se proporciona un rango de
plausibilidad para la hipótesis en cuestión, permitiendo así que los datos influyan más sobre la
distribución posterior. Por supuesto, como veremos a continuación, el efecto de una distribución
prior subjetiva se disipará en la medida en que el volumen de datos sea más grande, i.e., el efecto
de los datos dominara sobre nuestro grado de conocimiento de los mismos a través de la hipótesis
planteada.

Es importante notar que no todo prior plano es objetivo, si por ejemplo, el rango de plausibilidad
se restringe a uno más corto que el rango que incluye todas las posibilidades, entonces la
distribución prior es subjetiva. De igual manera, una distribución prior no plana no necesariamente
es subjetiva, pues una distribución prior pudo ser la distribución posterior de una inferencia
anterior a la obtención de los datos actuales o incluso, pudo ser la posterior de un problema
distinto. En estos casos decimos que la distribución prior está introduciendo dominio de
conocimiento sobre el modelo.

\section{Inferencia bayesiana: regresión lineal}

\section{Efecto del prior}
%
En esta sección veremos como la elección de la distribución prior puede afectar significativamente
nuestra inferencia y como depende dicho efecto en la cantidad de los datos y en la forma del prior.

Para cuantificar el efecto del prior, estudiaré la dependencia de la diferencia entre las
distribuciones posteriores obtenidas usando un prior objetivo y uno subjetivo, como función del
número de datos observados.

\begin{description}
%
\item[\textit{\color{teal} Dependencia con la cantidad de datos.}] Supongamos que la distribución
\emph{likelihood} dado un conjunto de datos $\dat$ es
%
$$
P(\dat|\hip,I) = \prod_{i=1}^N P(\mathcal{D}_i|\hip,I)
$$
%
entonces la log-posterior es simplemente
%
$$
\log{P(\hip|\dat,I)} = \sum_{i=1}^N\mathcal{L}(\mathcal{D}_i|\hip,I) + \log{P(\hip|I)} + K,
$$
%
donde $\mathcal{L}(\dat|\hip,I)\equiv\log{P(\dat|\hip,I)}$ y $K$ es una constante. Es claro entonces
que la distribución posterior escala con $N$, el número de datos. Esto tiene sentido intuitivamente
hablando, porque es de esperarse que en el límite de $N\to\infty$ la información que proveen los
datos acerca de nuestra inferencia sea más relevante que la de la distribución prior.
%
\item[\textit{\color{teal} Dependencia con la forma del prior.}] Es de esperarse que nuestra
inferencia estadística sea fuertemente dependiente de nuestra elección de la distribución prior en
el límite de pocos datos, aún cuando el prior sea objetivo. Sin embargo, siempre tendremos la
oportunidad de introducir nuestros prejuicios (aún cuando $N\to\infty$) si el prior es lo
suficientemente subjetivo o mejor dicho, informativo.
%
\end{description}

\subsection*{¿Cómo elegir priors de manera apropiada?}
%
Por supuesto la elección de la distribución de probabilidad prior depende del problema en particular
que se quiera resolver. Por ejemplo, si el científico se siente muy confiado sobre sus prejuicios
podría sentirse tentado también a introducir un prior informativo, mientras que si por el contrario
tiene poco conocimiento del problema lo mejor sería asumir un prior objetivo. Como hemos visto
anteriormente, independientemente del prior que se


\section{Muestreo de la posterior}
%
Existen varias formas de muestrar la posterior y la eficiencia de la técnica adoptada dependerá
exclusivamente de la naturaleza del problema reflejada en la forma de la distribución posterior. Por
ejemplo, si la distribución posterior se puede escribir analíticamente, no será necesario recurrir a
métodos numéricos como los algoritmos de Monte Carlo Markov Chain (MCMC). Si en cambio la
distribución posterior tiene una forma extraña que no se puede representar simplemente de manera
analítica, los métodos de muestreo aleatorio serán necesarios. Nótese que esto también aplica a las
distribuciones prior, que también deben ser muestreadas aleatoriamente durante el proceso de
obtención de la distribución posterior en estos casos (me refiero a los casos de muestreo numérico).

Comencemos por los casos simples, en los que la posterior es simplemente representada por una
ecuación matemática. Definamos el concepto de distribución conjugada. Se llama distribución
conjugada a cualquier distribución perteneciente a la misma familia. Por ejemplo, en el contexto de
la estadística bayesiana, si la distribución prior y la distribución posterior son familias, se dice
que el prior es el conjudado de la posterior y viceversa.

\section{Marginalización}

\section{Chequeo del modelo}

\section{Ejemplo: X}

\section{Epílogo}

\appendix

\section{Distribuciones conjugadas}\label{sc:conjugate-pdf}

\section{Método de máxima entropía}\label{sc:me-method}

Supongamos que tenemos información constrastable sobre una hipótesis $\hip$ y queremos asignar una
distribución de probabilidad que cumpla con esa condición y con la condición de que la distribución
represente en sí una distribución de probabilidad, i.e. que se cumple la condición \eqref{ec:norm}
¿cuál es la forma más \emph{justa} de asignar dicha distribución de probabilidad?

\end{document}
